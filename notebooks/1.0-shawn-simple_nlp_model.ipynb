{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple NLP model for TinyStories dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shawn/Documents/sjsu/2025-1/DL_CMPE258/TinyStoriesProject\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import re\n",
    "from collections import Counter\n",
    "import os\n",
    "import sys\n",
    "\n",
    "current_path = os.path.abspath('.')\n",
    "project_name = 'TinyStoriesProject'\n",
    "project_path = os.path.join(current_path.split(project_name)[0], project_name)\n",
    "print(project_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(\"roneneldan/TinyStories\", split=\"train\")\n",
    "valid_dataset = load_dataset(\"roneneldan/TinyStories\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total train dataset length = 2119719\n",
      "total valid dataset length = 21990\n"
     ]
    }
   ],
   "source": [
    "print(f'total train dataset length = {len(train_dataset)}')\n",
    "print(f'total valid dataset length = {len(valid_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One day, a little girl named Lily found a needle in her room. She knew it was difficult to play with it because it was sharp. Lily wanted to share the needle with her mom, so she could sew a button on her shirt.\n",
      "\n",
      "Lily went to her mom and said, \"Mom, I found this needle. Can you share it with me and sew my shirt?\" Her mom smiled and said, \"Yes, Lily, we can share the needle and fix your shirt.\"\n",
      "\n",
      "Together, they shared the needle and sewed the button on Lily's shirt. It was not difficult for them because they were sharing and helping each other. After they finished, Lily thanked her mom for sharing the needle and fixing her shirt. They both felt happy because they had shared and worked together.\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "959\n",
      "Lily and Ben were friends. They liked to play with toys and run in the park. One day, they found a big cake on the table. It looked yummy and sweet. They wanted to eat some.\n",
      "\n",
      "But Mom said, \"No, no, no. That cake is for Grandma's birthday. You can't have any. It is not for you.\"\n",
      "\n",
      "Lily and Ben were sad and angry. They did not like Mom's words. They did not want to wait for Grandma. They wanted cake now.\n",
      "\n",
      "They had a bad idea. They decided to sneak some cake when Mom was not looking. They took a big knife and cut a slice. They put it on a plate and ran to the corner.\n",
      "\n",
      "They took a bite of the cake. But it was not yummy and sweet. It was disgusting and bitter. It had salt and pepper and vinegar and mustard and garlic and onion and cheese and fish and pickle and soap and dirt and bugs and worms and hair and nails and glass and metal and rocks and sticks and bones and blood and poop and pee and spit and snot and pus and vomit and slime and goo and mold and rot and rust and dust and ash and trash and fire and ice and pain and hate and death and doom and gloom and fear and tears and screams and nightmares and curses and sins and hell and evil and darkness and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and\n"
     ]
    }
   ],
   "source": [
    "max_length = 0\n",
    "max_story = None\n",
    "for story in train_dataset:\n",
    "    length = len(story['text'].split(' '))\n",
    "    if length > max_length:\n",
    "        max_story = story['text']\n",
    "        max_length = length\n",
    "\n",
    "for story in valid_dataset:\n",
    "    length = len(story['text'].split(' '))\n",
    "    if length > max_length:\n",
    "        max_story = story['text']\n",
    "        max_length = length\n",
    "\n",
    "print(max_length)\n",
    "print(max_story)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'day', 'a', 'little', 'girl', 'named', 'lily', 'found', 'a', 'needle', 'in', 'her', 'room', 'she', 'knew', 'it', 'was', 'difficult', 'to', 'play', 'with', 'it', 'because', 'it', 'was', 'sharp', 'lily', 'wanted', 'to', 'share', 'the', 'needle', 'with', 'her', 'mom', 'so', 'she', 'could', 'sew', 'a', 'button', 'on', 'her', 'shirt', 'lily', 'went', 'to', 'her', 'mom', 'and', 'said', 'mom', 'i', 'found', 'this', 'needle', 'can', 'you', 'share', 'it', 'with', 'me', 'and', 'sew', 'my', 'shirt', 'her', 'mom', 'smiled', 'and', 'said', 'yes', 'lily', 'we', 'can', 'share', 'the', 'needle', 'and', 'fix', 'your', 'shirt', 'together', 'they', 'shared', 'the', 'needle', 'and', 'sewed', 'the', 'button', 'on', 'lily', 's', 'shirt', 'it', 'was', 'not', 'difficult', 'for', 'them', 'because', 'they', 'were', 'sharing', 'and', 'helping', 'each', 'other', 'after', 'they', 'finished', 'lily', 'thanked', 'her', 'mom', 'for', 'sharing', 'the', 'needle', 'and', 'fixing', 'her', 'shirt', 'they', 'both', 'felt', 'happy', 'because', 'they', 'had', 'shared', 'and', 'worked', 'together']\n"
     ]
    }
   ],
   "source": [
    "def simple_tokenize(text):\n",
    "    # Lowercase text\n",
    "    text = text.lower()\n",
    "    # Replace any punctuation/special-chars with spaces\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]+\", \" \", text)\n",
    "    # Split on whitespace\n",
    "    tokens = text.strip().split()\n",
    "    return tokens\n",
    "\n",
    "sample_token = simple_tokenize(train_dataset[0]['text'])\n",
    "print(sample_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(train_dataset, max_size=1000000):\n",
    "    \"\"\"\n",
    "    Build a vocabulary (word->index) from the training dataset.\n",
    "    We only keep the top 'max_size' tokens that appear at least 'min_freq' times.\n",
    "    \"\"\"\n",
    "    counter = Counter()\n",
    "    for example in train_dataset:\n",
    "        text = example[\"text\"]\n",
    "        tokens = simple_tokenize(text)\n",
    "        counter.update(tokens)\n",
    "\n",
    "    most_common = counter.most_common(max_size)\n",
    "    filtered = [(token, freq) for token, freq in most_common]\n",
    "    \n",
    "    # Reserve some special tokens\n",
    "    # <pad> for padding, <unk> for unknown words, <bos> for beginning of sequence, <eos> for end of sequence.\n",
    "    # <unk> for unkown words because there are words we don't know in validation data.\n",
    "    special_tokens = [\"<pad>\", \"<unk>\", \"<bos>\", \"<eos>\"]\n",
    "    \n",
    "    vocab = special_tokens + [token for token, _ in filtered]\n",
    "    word2idx = {w: i for i, w in enumerate(vocab)}\n",
    "    \n",
    "    return vocab, word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyStoriesDataset(Dataset):\n",
    "    def __init__(self, dataset, word2idx, max_length=50, overlap=25):\n",
    "        self.dataset = dataset\n",
    "        self.word2idx = word2idx\n",
    "        self.max_length = max_length\n",
    "        self.overlap = overlap\n",
    "\n",
    "        self.processed_stories = []\n",
    "        \n",
    "        for data in dataset:\n",
    "            text = data['text']\n",
    "            tokens = ['<bos>'] + simple_tokenize(text) + ['<eos>']\n",
    "            token_ids = [word2idx[t] if t in word2idx else word2idx[\"<unk>\"] for t in tokens]\n",
    "\n",
    "            if len(token_ids) <= max_length:\n",
    "                self.processed_stories.append(token_ids)\n",
    "                continue\n",
    "        \n",
    "            # if story is too long, we split\n",
    "            start_idx = 0\n",
    "            while start_idx < len(token_ids):\n",
    "                end_idx = min(start_idx + max_length, len(token_ids))\n",
    "                chunk = token_ids[start_idx: end_idx]\n",
    "\n",
    "                if len(chunk) < max_length // 2:\n",
    "                    break\n",
    "                    \n",
    "                self.processed_stories.append(chunk)\n",
    "                start_idx += (end_idx - overlap)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.processed_stories)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Return input_ids and target_ids for next token prediction.\n",
    "        \n",
    "        For a sequence [w1, w2, w3, w4],\n",
    "        input_ids = [w1, w2, w3]\n",
    "        target_ids = [w2, w3, w4] (the sequence shifted by 1).\n",
    "        \n",
    "        Padding will be handled in outer function\n",
    "        \"\"\"\n",
    "        token_ids = self.processed_stories[idx]\n",
    "        input_ids = token_ids[:-1]\n",
    "        target_ids = token_ids[1:]\n",
    "        \n",
    "        return torch.tensor(input_ids, dtype=torch.long), torch.tensor(target_ids, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_fn(batch):\n",
    "    input_ids_list, target_ids_list = zip(*batch)\n",
    "    max_len = max(len(x) for x in input_ids_list)\n",
    "\n",
    "    padded_inputs = []\n",
    "    padded_targets = []\n",
    "\n",
    "    for input, target in zip(input_ids_list, target_ids_list):\n",
    "        pad_len = max_len - len(input)\n",
    "        input_padded = torch.cat([input, torch.zeros(pad_len, dtype=torch.long)])  # possible because we used <pad> as 0\n",
    "        target_padded = torch.cat([target, torch.zeros(pad_len, dtype=torch.long)])\n",
    "\n",
    "        padded_inputs.append(input_padded)\n",
    "        padded_targets.append(target_padded)\n",
    "\n",
    "    padded_inputs = torch.stack(padded_inputs, dim=0)\n",
    "    padded_targets = torch.stack(padded_targets, dim=0)\n",
    "\n",
    "    return padded_inputs, padded_targets\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 42537\n"
     ]
    }
   ],
   "source": [
    "vocab, word2idx = build_vocab(train_dataset)\n",
    "\n",
    "idx2word = {i: w for w, i in word2idx.items()}\n",
    "vocab_size = len(vocab)\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "\n",
    "train_data = TinyStoriesDataset(train_dataset, word2idx, max_length=50, overlap=15)\n",
    "valid_data = TinyStoriesDataset(valid_dataset, word2idx, max_length=50, overlap=15)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, collate_fn=padding_fn)\n",
    "valid_loader = DataLoader(valid_data, batch_size=32, shuffle=False, collate_fn=padding_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_data, os.path.join(project_path, \"data/processed/index_encoded/train_dataset_ml50_ol15.pt\"))\n",
    "torch.save(valid_data, os.path.join(project_path, \"data/processed/index_encoded/valid_dataset_ml50_ol15.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TransformerLM(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        d_model=256,       # embedding dimension\n",
    "        n_heads=4,         # number of attention heads\n",
    "        num_layers=4,      # number of Transformer blocks\n",
    "        dim_feedforward=512,\n",
    "        max_seq_len=512,\n",
    "        dropout=0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Token embedding\n",
    "        self.token_emb = nn.Embedding(vocab_size, d_model)\n",
    "        # Positional embedding\n",
    "        self.pos_emb = nn.Embedding(max_seq_len, d_model)\n",
    "        \n",
    "        # Transformer blocks\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model, n_heads, dim_feedforward, dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        \n",
    "        # Final linear layer to predict next token\n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.max_seq_len = max_seq_len\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x shape: (batch_size, seq_len)\n",
    "        We return logits of shape (batch_size, seq_len, vocab_size).\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = x.shape\n",
    "        \n",
    "        # 1) Create token embeddings\n",
    "        token_embs = self.token_emb(x)  # (batch_size, seq_len, d_model)\n",
    "        \n",
    "        # 2) Create positional embeddings\n",
    "        #    Positions: [0, 1, 2, ..., seq_len-1]\n",
    "        positions = torch.arange(0, seq_len, device=x.device).unsqueeze(0)  # (1, seq_len)\n",
    "        pos_embs = self.pos_emb(positions)  # (1, seq_len, d_model)\n",
    "        \n",
    "        # 3) Sum token + positional embeddings\n",
    "        embeddings = token_embs + pos_embs  # (batch_size, seq_len, d_model)\n",
    "        \n",
    "        # 4) Transformer Encoder expects (seq_len, batch_size, d_model)\n",
    "        embeddings = embeddings.transpose(0, 1)  # (seq_len, batch_size, d_model)\n",
    "        \n",
    "        # 5) Generate an attention mask to prevent attending to future positions\n",
    "        #    For language modeling, we typically want a causal mask (no future positions).\n",
    "        #    We'll create a standard upper-triangular mask for seq_len x seq_len.\n",
    "        device = x.device\n",
    "        mask = torch.triu(torch.ones(seq_len, seq_len, device=device), diagonal=1).bool()\n",
    "        \n",
    "        # 6) Pass through the Transformer encoder\n",
    "        encoded = self.transformer_encoder(embeddings, mask=mask)  # (seq_len, batch_size, d_model)\n",
    "        \n",
    "        # 7) Project back to vocab size\n",
    "        logits = self.fc_out(encoded)  # (seq_len, batch_size, vocab_size)\n",
    "        \n",
    "        # 8) Reshape to (batch_size, seq_len, vocab_size)\n",
    "        logits = logits.transpose(0, 1)\n",
    "        \n",
    "        return logits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tinystoriesproject-PsthS1z7-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
