{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple NLP model for TinyStories dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shawn/Library/Caches/pypoetry/virtualenvs/tinystoriesproject-PsthS1z7-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shawn/Documents/sjsu/2025-1/DL_CMPE258/TinyStoriesProject\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import re\n",
    "from collections import Counter\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "current_path = os.path.abspath('.')\n",
    "project_name = 'TinyStoriesProject'\n",
    "project_path = os.path.join(current_path.split(project_name)[0], project_name)\n",
    "sys.path.append(project_path)\n",
    "print(project_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(\"roneneldan/TinyStories\", split=\"train\")\n",
    "valid_dataset = load_dataset(\"roneneldan/TinyStories\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total train dataset length = 2119719\n",
      "total valid dataset length = 21990\n"
     ]
    }
   ],
   "source": [
    "print(f'total train dataset length = {len(train_dataset)}')\n",
    "print(f'total valid dataset length = {len(valid_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One day, a little girl named Lily found a needle in her room. She knew it was difficult to play with it because it was sharp. Lily wanted to share the needle with her mom, so she could sew a button on her shirt.\n",
      "\n",
      "Lily went to her mom and said, \"Mom, I found this needle. Can you share it with me and sew my shirt?\" Her mom smiled and said, \"Yes, Lily, we can share the needle and fix your shirt.\"\n",
      "\n",
      "Together, they shared the needle and sewed the button on Lily's shirt. It was not difficult for them because they were sharing and helping each other. After they finished, Lily thanked her mom for sharing the needle and fixing her shirt. They both felt happy because they had shared and worked together.\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "959\n",
      "Lily and Ben were friends. They liked to play with toys and run in the park. One day, they found a big cake on the table. It looked yummy and sweet. They wanted to eat some.\n",
      "\n",
      "But Mom said, \"No, no, no. That cake is for Grandma's birthday. You can't have any. It is not for you.\"\n",
      "\n",
      "Lily and Ben were sad and angry. They did not like Mom's words. They did not want to wait for Grandma. They wanted cake now.\n",
      "\n",
      "They had a bad idea. They decided to sneak some cake when Mom was not looking. They took a big knife and cut a slice. They put it on a plate and ran to the corner.\n",
      "\n",
      "They took a bite of the cake. But it was not yummy and sweet. It was disgusting and bitter. It had salt and pepper and vinegar and mustard and garlic and onion and cheese and fish and pickle and soap and dirt and bugs and worms and hair and nails and glass and metal and rocks and sticks and bones and blood and poop and pee and spit and snot and pus and vomit and slime and goo and mold and rot and rust and dust and ash and trash and fire and ice and pain and hate and death and doom and gloom and fear and tears and screams and nightmares and curses and sins and hell and evil and darkness and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and nothing and\n"
     ]
    }
   ],
   "source": [
    "max_length = 0\n",
    "max_story = None\n",
    "for story in train_dataset:\n",
    "    length = len(story['text'].split(' '))\n",
    "    if length > max_length:\n",
    "        max_story = story['text']\n",
    "        max_length = length\n",
    "\n",
    "for story in valid_dataset:\n",
    "    length = len(story['text'].split(' '))\n",
    "    if length > max_length:\n",
    "        max_story = story['text']\n",
    "        max_length = length\n",
    "\n",
    "print(max_length)\n",
    "print(max_story)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'day', 'a', 'little', 'girl', 'named', 'lily', 'found', 'a', 'needle', 'in', 'her', 'room', 'she', 'knew', 'it', 'was', 'difficult', 'to', 'play', 'with', 'it', 'because', 'it', 'was', 'sharp', 'lily', 'wanted', 'to', 'share', 'the', 'needle', 'with', 'her', 'mom', 'so', 'she', 'could', 'sew', 'a', 'button', 'on', 'her', 'shirt', 'lily', 'went', 'to', 'her', 'mom', 'and', 'said', 'mom', 'i', 'found', 'this', 'needle', 'can', 'you', 'share', 'it', 'with', 'me', 'and', 'sew', 'my', 'shirt', 'her', 'mom', 'smiled', 'and', 'said', 'yes', 'lily', 'we', 'can', 'share', 'the', 'needle', 'and', 'fix', 'your', 'shirt', 'together', 'they', 'shared', 'the', 'needle', 'and', 'sewed', 'the', 'button', 'on', 'lily', 's', 'shirt', 'it', 'was', 'not', 'difficult', 'for', 'them', 'because', 'they', 'were', 'sharing', 'and', 'helping', 'each', 'other', 'after', 'they', 'finished', 'lily', 'thanked', 'her', 'mom', 'for', 'sharing', 'the', 'needle', 'and', 'fixing', 'her', 'shirt', 'they', 'both', 'felt', 'happy', 'because', 'they', 'had', 'shared', 'and', 'worked', 'together']\n"
     ]
    }
   ],
   "source": [
    "def simple_tokenize(text):\n",
    "    # Lowercase text\n",
    "    text = text.lower()\n",
    "    # Replace any punctuation/special-chars with spaces\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]+\", \" \", text)\n",
    "    # Split on whitespace\n",
    "    tokens = text.strip().split()\n",
    "    return tokens\n",
    "\n",
    "sample_token = simple_tokenize(train_dataset[0]['text'])\n",
    "print(sample_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(train_dataset, max_size=1000000):\n",
    "    \"\"\"\n",
    "    Build a vocabulary (word->index) from the training dataset.\n",
    "    We only keep the top 'max_size' tokens that appear at least 'min_freq' times.\n",
    "    \"\"\"\n",
    "    counter = Counter()\n",
    "    for example in train_dataset:\n",
    "        text = example[\"text\"]\n",
    "        tokens = simple_tokenize(text)\n",
    "        counter.update(tokens)\n",
    "\n",
    "    most_common = counter.most_common(max_size)\n",
    "    filtered = [(token, freq) for token, freq in most_common]\n",
    "    \n",
    "    # Reserve some special tokens\n",
    "    # <pad> for padding, <unk> for unknown words, <bos> for beginning of sequence, <eos> for end of sequence.\n",
    "    # <unk> for unkown words because there are words we don't know in validation data.\n",
    "    special_tokens = [\"<pad>\", \"<unk>\", \"<bos>\", \"<eos>\"]\n",
    "    \n",
    "    vocab = special_tokens + [token for token, _ in filtered]\n",
    "    word2idx = {w: i for i, w in enumerate(vocab)}\n",
    "    \n",
    "    return vocab, word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyStoriesDataset(Dataset):\n",
    "    def __init__(self, dataset, word2idx, max_length=50, overlap=25):\n",
    "        self.dataset = dataset\n",
    "        self.word2idx = word2idx\n",
    "        self.max_length = max_length\n",
    "        self.overlap = overlap\n",
    "\n",
    "        self.processed_stories = []\n",
    "        \n",
    "        for data in dataset:\n",
    "            text = data['text']\n",
    "            tokens = ['<bos>'] + simple_tokenize(text) + ['<eos>']\n",
    "            token_ids = [word2idx[t] if t in word2idx else word2idx[\"<unk>\"] for t in tokens]\n",
    "\n",
    "            if len(token_ids) <= max_length:\n",
    "                self.processed_stories.append(token_ids)\n",
    "                continue\n",
    "        \n",
    "            # if story is too long, we split\n",
    "            start_idx = 0\n",
    "            while start_idx < len(token_ids):\n",
    "                end_idx = min(start_idx + max_length, len(token_ids))\n",
    "                chunk = token_ids[start_idx: end_idx]\n",
    "\n",
    "                if len(chunk) < max_length // 2:\n",
    "                    break\n",
    "                    \n",
    "                self.processed_stories.append(chunk)\n",
    "                start_idx += (end_idx - overlap)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.processed_stories)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Return input_ids and target_ids for next token prediction.\n",
    "        \n",
    "        For a sequence [w1, w2, w3, w4],\n",
    "        input_ids = [w1, w2, w3]\n",
    "        target_ids = [w2, w3, w4] (the sequence shifted by 1).\n",
    "        \n",
    "        Padding will be handled in outer function\n",
    "        \"\"\"\n",
    "        token_ids = self.processed_stories[idx]\n",
    "        input_ids = token_ids[:-1]\n",
    "        target_ids = token_ids[1:]\n",
    "        \n",
    "        return torch.tensor(input_ids, dtype=torch.long), torch.tensor(target_ids, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTinyStoriesDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Not using sliding windows\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, word2idx, max_length=50):\n",
    "        self.dataset = dataset\n",
    "        self.word2idx = word2idx\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.processed_sequences = []\n",
    "        for data in dataset:\n",
    "            text = data['text']\n",
    "            tokens = ['<bos>'] + simple_tokenize(text) + ['<eos>']\n",
    "            token_ids = [word2idx[t] if t in word2idx else word2idx[\"<unk>\"] for t in tokens]\n",
    "            token_ids = token_ids[:self.max_length]\n",
    "            \n",
    "            self.processed_sequences.append(token_ids)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.processed_sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        token_ids = self.processed_sequences[idx]\n",
    "        input_ids = token_ids[:-1]\n",
    "        target_ids = token_ids[1:]\n",
    "\n",
    "        return torch.tensor(input_ids, dtype=torch.long), torch.tensor(target_ids, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_fn(batch):\n",
    "    input_ids_list, target_ids_list = zip(*batch)\n",
    "    max_len = max(len(x) for x in input_ids_list)\n",
    "\n",
    "    padded_inputs = []\n",
    "    padded_targets = []\n",
    "\n",
    "    for input, target in zip(input_ids_list, target_ids_list):\n",
    "        pad_len = max_len - len(input)\n",
    "        input_padded = torch.cat([input, torch.zeros(pad_len, dtype=torch.long)])  # possible because we used <pad> as 0\n",
    "        target_padded = torch.cat([target, torch.zeros(pad_len, dtype=torch.long)])\n",
    "\n",
    "        padded_inputs.append(input_padded)\n",
    "        padded_targets.append(target_padded)\n",
    "\n",
    "    padded_inputs = torch.stack(padded_inputs, dim=0)\n",
    "    padded_targets = torch.stack(padded_targets, dim=0)\n",
    "\n",
    "    return padded_inputs, padded_targets\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 42537\n",
      "Dataset time: 242.64\n",
      "Data loader time: 0.00\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "vocab, word2idx = build_vocab(train_dataset)\n",
    "\n",
    "idx2word = {i: w for w, i in word2idx.items()}\n",
    "vocab_size = len(vocab)\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "\n",
    "train_data = TinyStoriesDataset(train_dataset, word2idx, max_length=50, overlap=15)\n",
    "valid_data = TinyStoriesDataset(valid_dataset, word2idx, max_length=50, overlap=15)\n",
    "\n",
    "print(f\"Dataset time: {time.time() - t:.2f}\")\n",
    "t = time.time()\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, collate_fn=padding_fn, num_workers=0)\n",
    "valid_loader = DataLoader(valid_data, batch_size=32, shuffle=False, collate_fn=padding_fn, num_workers=0)\n",
    "\n",
    "print(f\"Data loader time: {time.time() - t:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 42537\n",
      "Dataset time: 268.97\n",
      "Data loader time: 0.00\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "vocab, word2idx = build_vocab(train_dataset)\n",
    "\n",
    "idx2word = {i: w for w, i in word2idx.items()}\n",
    "vocab_size = len(vocab)\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "\n",
    "simple_train_data = SimpleTinyStoriesDataset(train_dataset, word2idx, max_length=50)\n",
    "simple_valid_data = SimpleTinyStoriesDataset(valid_dataset, word2idx, max_length=50)\n",
    "\n",
    "print(f\"Dataset time: {time.time() - t:.2f}\")\n",
    "t = time.time()\n",
    "\n",
    "simple_train_loader = DataLoader(simple_train_data, batch_size=32, shuffle=True, collate_fn=padding_fn, num_workers=0)\n",
    "simple_valid_loader = DataLoader(simple_valid_data, batch_size=32, shuffle=False, collate_fn=padding_fn, num_workers=0)\n",
    "\n",
    "print(f\"Data loader time: {time.time() - t:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TransformerDecoderLM(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        d_model=256,       # embedding dimension\n",
    "        n_heads=4,         # number of attention heads\n",
    "        num_layers=4,      # number of Transformer blocks\n",
    "        dim_feedforward=512,\n",
    "        max_seq_len=512,\n",
    "        dropout=0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.token_emb = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_emb = nn.Embedding(max_seq_len, d_model)\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.TransformerDecoderLayer(d_model, n_heads, dim_feedforward, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.max_seq_len = max_seq_len\n",
    "        \n",
    "    def forward(self, input_ids):\n",
    "        batch_size, seq_len = input_ids.shape\n",
    "        \n",
    "        token_embs = self.token_emb(input_ids)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        positions = torch.arange(0, seq_len, device=input_ids.device).unsqueeze(0)\n",
    "        pos_embs = self.pos_emb(positions)  # (1, seq_len, d_model)\n",
    "\n",
    "        embeddings = token_embs + pos_embs  # (batch_size, seq_len, d_model)\n",
    "        embeddings = embeddings.transpose(0, 1)\n",
    "\n",
    "        mask = torch.triu(torch.ones(seq_len, seq_len, device=input_ids.device), diagonal=1).bool()\n",
    "        for layer in self.layers:\n",
    "            embeddings = layer(embeddings, embeddings, tgt_mask=mask)\n",
    "\n",
    "        logits = self.fc_out(embeddings).transpose(0, 1)  # (batch_size, seq_len, vocab_size)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11329321\n"
     ]
    }
   ],
   "source": [
    "model = TransformerDecoderLM(vocab_size=vocab_size, d_model=128, n_heads=2, num_layers=2, dim_feedforward=128)\n",
    "params_cnt = sum(param.numel() for param in model.parameters())\n",
    "print(params_cnt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total paramters are 24M, which is a good amount for small language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, optimizer, device, vocab_size):\n",
    "    t = time.time()\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        input_ids, target_ids = [b.to(device) for b in batch]\n",
    "        logits = model(input_ids)\n",
    "        logits = logits.reshape(-1, vocab_size)\n",
    "        targets = target_ids.reshape(-1)\n",
    "\n",
    "        loss = F.cross_entropy(logits, targets, ignore_index=0)\n",
    "        total_loss += loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 10000 == 0:\n",
    "            print(f\"batch {i}: {time.time() - t:.2f}\")\n",
    "            t = time.time()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, device, vocab_size):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids, target_ids = [b.to(device) for b in batch]\n",
    "            \n",
    "            logits = model(input_ids)  # (batch_size, seq_len, vocab_size)\n",
    "            logits = logits.reshape(-1, vocab_size)\n",
    "            targets_reshaped = target_ids.reshape(-1)\n",
    "            \n",
    "            loss = F.cross_entropy(logits, targets_reshaped, ignore_index=0)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_text(model, prompt, word2idx, idx2word, max_new_tokens=30, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    model:        Our language model\n",
    "    prompt:       A string prompt\n",
    "    word2idx:     The vocabulary mapping from tokens to indices\n",
    "    idx2word:     The inverse vocabulary mapping\n",
    "    max_new_tokens: The maximum number of tokens to generate\n",
    "    device:       \"cpu\" or \"cuda\"\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    tokens = simple_tokenize(prompt.lower())\n",
    "    \n",
    "    # Convert to token IDs\n",
    "    input_ids = [word2idx[\"<bos>\"]]  # start with <bos>\n",
    "    for t in tokens:\n",
    "        input_ids.append(word2idx[t] if t in word2idx else word2idx[\"<unk>\"])\n",
    "    \n",
    "    # Move to tensor\n",
    "    input_ids = torch.tensor([input_ids], dtype=torch.long, device=device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_new_tokens):\n",
    "            # Get logits for the current sequence\n",
    "            logits = model(input_ids)  # (batch_size=1, seq_len, vocab_size)\n",
    "            \n",
    "            # Take the last timestep\n",
    "            logits_last = logits[:, -1, :]  # (1, vocab_size)\n",
    "            \n",
    "            # Greedy pick\n",
    "            next_token_id = torch.argmax(logits_last, dim=-1)  # (1,)\n",
    "            \n",
    "            # Append the predicted token\n",
    "            input_ids = torch.cat([input_ids, next_token_id.unsqueeze(0)], dim=1)  # shape: (1, seq_len+1)\n",
    "            \n",
    "            # If we hit <eos>, we can stop early\n",
    "            if next_token_id.item() == word2idx[\"<eos>\"]:\n",
    "                break\n",
    "    \n",
    "    # Convert token IDs back to text (skipping initial <bos>)\n",
    "    generated_ids = input_ids[0].tolist()\n",
    "    # The first token is <bos>, skip that for printing\n",
    "    generated_ids = generated_ids[1:]\n",
    "    \n",
    "    # Stop if we see <eos>\n",
    "    if word2idx[\"<eos>\"] in generated_ids:\n",
    "        eos_pos = generated_ids.index(word2idx[\"<eos>\"])\n",
    "        generated_ids = generated_ids[:eos_pos]\n",
    "    \n",
    "    generated_words = [idx2word[idx] for idx in generated_ids]\n",
    "    \n",
    "    return \" \".join(generated_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============EPOCH 000 TRAINIG=================\n",
      "batch 0: 1.15\n",
      "batch 10000: 4304.00\n",
      "batch 20000: 2603.23\n",
      "batch 30000: 1226.73\n",
      "batch 40000: 1057.74\n",
      "batch 50000: 1061.85\n",
      "batch 60000: 2758.75\n",
      "batch 70000: 1084.28\n",
      "batch 80000: 1086.91\n",
      "batch 90000: 1079.12\n",
      "batch 100000: 1058.44\n",
      "batch 110000: 1054.31\n",
      "batch 120000: 1078.14\n",
      "batch 130000: 1074.79\n",
      "batch 140000: 1087.31\n",
      "batch 150000: 7048.28\n",
      "batch 160000: 7391.83\n",
      "batch 170000: 6186.90\n",
      "batch 180000: 6337.92\n",
      "batch 190000: 5771.79\n",
      "Epoch 1/10, Train Loss: 0.1072, Valid Loss: 0.0677\n",
      "===============EPOCH 001 TRAINIG=================\n",
      "batch 0: 0.27\n",
      "batch 10000: 1187.35\n",
      "batch 20000: 4093.66\n",
      "batch 30000: 1068.52\n",
      "batch 40000: 1053.23\n",
      "batch 50000: 1058.50\n",
      "batch 60000: 1849.67\n",
      "batch 70000: 1235.81\n",
      "batch 80000: 1063.00\n",
      "batch 90000: 1061.04\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m===============EPOCH \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m TRAINIG=================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m evaluate(model, valid_loader, device, vocab_size)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Valid Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[16], line 16\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, dataloader, optimizer, device, vocab_size)\u001b[0m\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     15\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 16\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10000\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mt\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/tinystoriesproject-PsthS1z7-py3.10/lib/python3.10/site-packages/torch/optim/optimizer.py:493\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    490\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 493\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/tinystoriesproject-PsthS1z7-py3.10/lib/python3.10/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/tinystoriesproject-PsthS1z7-py3.10/lib/python3.10/site-packages/torch/optim/adamw.py:243\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    230\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m cast(Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m], group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    232\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    233\u001b[0m         group,\n\u001b[1;32m    234\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    240\u001b[0m         state_steps,\n\u001b[1;32m    241\u001b[0m     )\n\u001b[0;32m--> 243\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/tinystoriesproject-PsthS1z7-py3.10/lib/python3.10/site-packages/torch/optim/optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/tinystoriesproject-PsthS1z7-py3.10/lib/python3.10/site-packages/torch/optim/adamw.py:875\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    873\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 875\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/tinystoriesproject-PsthS1z7-py3.10/lib/python3.10/site-packages/torch/optim/adamw.py:426\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m    425\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mlerp_(grad, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m device_beta1)\n\u001b[0;32m--> 426\u001b[0m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n\u001b[1;32m    429\u001b[0m     step \u001b[38;5;241m=\u001b[39m step_t\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n",
    "model = TransformerDecoderLM(vocab_size=vocab_size, d_model=256, n_heads=4, num_layers=4, dim_feedforward=512)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define an optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10  # For demonstration; adjust as needed\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"===============EPOCH {epoch:03} TRAINIG=================\")\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, device, vocab_size)\n",
    "    val_loss = evaluate(model, valid_loader, device, vocab_size)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Valid Loss: {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Once upon a time\n",
      "Generated: once upon a time once upon time once upon time once upon time once upon time time time once upon time time once upon time time time time time time time time time time\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Once upon a time\"\n",
    "generated = generate_text(model, prompt, word2idx, idx2word, max_new_tokens=30, device=device)\n",
    "print(\"Prompt:\", prompt)\n",
    "print(\"Generated:\", generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tinystoriesproject-PsthS1z7-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
